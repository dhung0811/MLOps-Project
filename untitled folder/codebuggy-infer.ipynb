{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b6c4bdd2",
      "metadata": {},
      "source": [
        "# CodeBuggy Inference (code + diff)\n",
        "\n",
        "Nhap code buggy va diff (unified diff) de suy ra fixed code, sau do chay model RGCN de du doan bug o muc do graph va node."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b9755324",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/hungnguyen/dacn/untitled folder/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "import torch\n",
        "import numpy as np\n",
        "import javalang\n",
        "import joblib\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from torch_geometric.nn.conv import RGCNConv\n",
        "\n",
        "from utils.gumtree_diff import GumTreeDiff, EditType\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "12b46c7d",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        }
      ],
      "source": [
        "GUMTREE_PATH = \"./gumtree-4.0.0-beta4/bin/gumtree\"\n",
        "MODEL_NAME = \"microsoft/graphcodebert-base\"\n",
        "NODE_TYPE_PATH = \"output/node_type_to_id.joblib\"\n",
        "CHECKPOINT_PATH = \"output/rgcn_detector.pt\"\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "RELATIONS = [\n",
        "    \"AST_CHILD\",\n",
        "    \"AST_PARENT\",\n",
        "    \"CFG_NEXT\",\n",
        "    \"CFG_TRUE\",\n",
        "    \"CFG_FALSE\",\n",
        "    \"CFG_LOOP\",\n",
        "    \"DEF_USE\",\n",
        "    \"USE_DEF\",\n",
        "    \"DIFF_PARENT\",\n",
        "    \"DIFF_SIBLING\",\n",
        "]\n",
        "RELATION_TO_ID = {r: i for i, r in enumerate(RELATIONS)}\n",
        "\n",
        "node_type_to_id = joblib.load(NODE_TYPE_PATH)\n",
        "gumtree_diff = GumTreeDiff(gumtree_path=GUMTREE_PATH)\n",
        "\n",
        "for candidate in [CHECKPOINT_PATH, \"output/rgcn_graphs/rgcn_detector.pt\"]:\n",
        "    if os.path.exists(candidate):\n",
        "        CHECKPOINT_PATH = candidate\n",
        "        break\n",
        "else:\n",
        "    raise FileNotFoundError(\n",
        "        \"Cannot find checkpoint. Tried output/rgcn_detector.pt and output/rgcn_graphs/rgcn_detector.pt\"\n",
        "    )\n",
        "\n",
        "checkpoint = torch.load(CHECKPOINT_PATH, weights_only=False, map_location=\"cpu\")\n",
        "\n",
        "class RGCNDetector(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_in_dim: int,\n",
        "        hidden_dim: int,\n",
        "        num_relations: int,\n",
        "        num_node_types: int,\n",
        "        node_type_emb_dim: int,\n",
        "        num_layers: int = 2,\n",
        "        dropout: float = 0.2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.base_in_dim = base_in_dim\n",
        "        self.node_type_emb_dim = node_type_emb_dim\n",
        "        self.node_type_emb = torch.nn.Embedding(num_node_types, node_type_emb_dim)\n",
        "        conv_in_dim = base_in_dim + node_type_emb_dim\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(RGCNConv(conv_in_dim, hidden_dim, num_relations=num_relations))\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.convs.append(RGCNConv(hidden_dim, hidden_dim, num_relations=num_relations))\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.node_head = torch.nn.Linear(hidden_dim, 1)\n",
        "        self.graph_head = torch.nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_type, batch = data.x, data.edge_index, data.edge_type, data.batch\n",
        "\n",
        "        if x.shape[1] == self.base_in_dim:\n",
        "            node_type_feats = self.node_type_emb(data.node_type_ids)\n",
        "            x = torch.cat([x, node_type_feats], dim=1)\n",
        "        elif x.shape[1] != self.base_in_dim + self.node_type_emb_dim:\n",
        "            raise ValueError(\n",
        "                f\"Unexpected x dim {x.shape[1]} (expected {self.base_in_dim} or {self.base_in_dim + self.node_type_emb_dim})\"\n",
        "            )\n",
        "\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index, edge_type)\n",
        "            x = torch.relu(x)\n",
        "            x = self.dropout(x)\n",
        "        node_logits = self.node_head(x).squeeze(-1)\n",
        "        graph_emb = global_mean_pool(x, batch)\n",
        "        graph_logits = self.graph_head(graph_emb).squeeze(-1)\n",
        "        return node_logits, graph_logits\n",
        "\n",
        "\n",
        "model = RGCNDetector(\n",
        "    base_in_dim=checkpoint[\"base_in_dim\"],\n",
        "    hidden_dim=checkpoint[\"hidden_dim\"],\n",
        "    num_relations=len(checkpoint[\"relations\"]),\n",
        "    num_node_types=len(node_type_to_id),\n",
        "    node_type_emb_dim=64,\n",
        ").to(DEVICE)\n",
        "model.load_state_dict(checkpoint[\"model_state\"])\n",
        "model.eval()\n",
        "\n",
        "print(f\"Device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "31520151",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "encoder = AutoModel.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "encoder.eval()\n",
        "\n",
        "STATEMENT_NODES = {\n",
        "    \"StatementExpression\",\n",
        "    \"ReturnStatement\",\n",
        "    \"IfStatement\",\n",
        "    \"ForStatement\",\n",
        "    \"WhileStatement\",\n",
        "    \"DoStatement\",\n",
        "    \"SwitchStatement\",\n",
        "    \"TryStatement\",\n",
        "    \"ThrowStatement\",\n",
        "    \"BreakStatement\",\n",
        "    \"ContinueStatement\",\n",
        "    \"BlockStatement\",\n",
        "}\n",
        "\n",
        "WRAP_TEMPLATE = \"\"\"public class Dummy {{\n",
        "    {method_code}\n",
        "}}\"\"\"\n",
        "\n",
        "\n",
        "def wrap_method(method_code: str) -> str:\n",
        "    return WRAP_TEMPLATE.format(method_code=method_code)\n",
        "\n",
        "\n",
        "def iter_children(node):\n",
        "    for child in node.children:\n",
        "        if child is None:\n",
        "            continue\n",
        "        if isinstance(child, list):\n",
        "            for item in child:\n",
        "                if item is not None:\n",
        "                    yield item\n",
        "        else:\n",
        "            yield child\n",
        "\n",
        "\n",
        "def get_node_label(node) -> str | None:\n",
        "    if hasattr(node, \"name\") and node.name:\n",
        "        return str(node.name)\n",
        "    if hasattr(node, \"member\") and node.member:\n",
        "        return str(node.member)\n",
        "    if hasattr(node, \"value\") and node.value is not None:\n",
        "        return str(node.value)\n",
        "    if hasattr(node, \"operator\") and node.operator:\n",
        "        return str(node.operator)\n",
        "    if hasattr(node, \"type\") and isinstance(node.type, str):\n",
        "        return str(node.type)\n",
        "    return None\n",
        "\n",
        "\n",
        "def compute_line_offsets(code: str) -> list[int]:\n",
        "    offsets = [0]\n",
        "    for idx, ch in enumerate(code):\n",
        "        if ch == \"\\n\":\n",
        "            offsets.append(idx + 1)\n",
        "    return offsets\n",
        "\n",
        "\n",
        "def line_col_to_offset(code: str, line: int, col: int) -> int | None:\n",
        "    if line <= 0 or col <= 0:\n",
        "        return None\n",
        "    line_offsets = compute_line_offsets(code)\n",
        "    if line > len(line_offsets):\n",
        "        return None\n",
        "    return line_offsets[line - 1] + (col - 1)\n",
        "\n",
        "\n",
        "def offset_to_line_col(code: str, offset: int) -> tuple[int, int]:\n",
        "    if offset < 0:\n",
        "        return (1, 1)\n",
        "    line_offsets = compute_line_offsets(code)\n",
        "    line = 1\n",
        "    for i, start in enumerate(line_offsets, 1):\n",
        "        if start <= offset:\n",
        "            line = i\n",
        "        else:\n",
        "            break\n",
        "    col = offset - line_offsets[line - 1] + 1\n",
        "    return (line, col)\n",
        "\n",
        "\n",
        "def build_ast_graph(code: str):\n",
        "    tree = javalang.parse.parse(wrap_method(code))\n",
        "\n",
        "    nodes = []\n",
        "    parents = []\n",
        "    children = []\n",
        "    id_to_index = {}\n",
        "\n",
        "    def is_wrapper(node) -> bool:\n",
        "        if isinstance(node, javalang.tree.CompilationUnit):\n",
        "            return True\n",
        "        if isinstance(node, javalang.tree.ClassDeclaration) and getattr(node, \"name\", None) == \"Dummy\":\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def visit(node, parent_idx: int | None):\n",
        "        if not isinstance(node, javalang.tree.Node):\n",
        "            return\n",
        "        if is_wrapper(node):\n",
        "            for child in iter_children(node):\n",
        "                visit(child, parent_idx)\n",
        "            return\n",
        "\n",
        "        idx = len(nodes)\n",
        "        id_to_index[id(node)] = idx\n",
        "\n",
        "        label = get_node_label(node)\n",
        "        line = None\n",
        "        col = None\n",
        "        if getattr(node, \"position\", None):\n",
        "            line = node.position.line\n",
        "            col = node.position.column\n",
        "        start_pos = line_col_to_offset(code, line, col) if line and col else None\n",
        "        end_pos = start_pos + len(label) if (start_pos is not None and label) else start_pos\n",
        "\n",
        "        nodes.append(\n",
        "            {\n",
        "                \"raw\": node,\n",
        "                \"node_type\": node.__class__.__name__,\n",
        "                \"label\": label,\n",
        "                \"line\": line,\n",
        "                \"col\": col,\n",
        "                \"start_pos\": start_pos,\n",
        "                \"end_pos\": end_pos,\n",
        "            }\n",
        "        )\n",
        "        parents.append(parent_idx)\n",
        "        children.append([])\n",
        "        if parent_idx is not None:\n",
        "            children[parent_idx].append(idx)\n",
        "\n",
        "        for child in iter_children(node):\n",
        "            visit(child, idx)\n",
        "\n",
        "    visit(tree, None)\n",
        "\n",
        "    edges = []\n",
        "    edge_types = []\n",
        "\n",
        "    def add_edge(src: int, dst: int, rel: str):\n",
        "        edges.append((src, dst))\n",
        "        edge_types.append(RELATION_TO_ID[rel])\n",
        "\n",
        "    for parent_idx, child_list in enumerate(children):\n",
        "        for child_idx in child_list:\n",
        "            add_edge(parent_idx, child_idx, \"AST_CHILD\")\n",
        "            add_edge(child_idx, parent_idx, \"AST_PARENT\")\n",
        "\n",
        "    for parent_idx, child_list in enumerate(children):\n",
        "        stmt_children = [c for c in child_list if nodes[c][\"node_type\"] in STATEMENT_NODES]\n",
        "        for a, b in zip(stmt_children, stmt_children[1:]):\n",
        "            add_edge(a, b, \"CFG_NEXT\")\n",
        "\n",
        "    for idx, node in enumerate(nodes):\n",
        "        node_type = node[\"node_type\"]\n",
        "        raw = node[\"raw\"]\n",
        "\n",
        "        if node_type == \"IfStatement\":\n",
        "            then_node = getattr(raw, \"then_statement\", None)\n",
        "            else_node = getattr(raw, \"else_statement\", None)\n",
        "            then_idx = id_to_index.get(id(then_node))\n",
        "            else_idx = id_to_index.get(id(else_node))\n",
        "            if then_idx is not None:\n",
        "                add_edge(idx, then_idx, \"CFG_TRUE\")\n",
        "            if else_idx is not None:\n",
        "                add_edge(idx, else_idx, \"CFG_FALSE\")\n",
        "\n",
        "        if node_type in {\"ForStatement\", \"WhileStatement\", \"DoStatement\"}:\n",
        "            body = getattr(raw, \"body\", None)\n",
        "            body_idx = id_to_index.get(id(body))\n",
        "            if body_idx is not None:\n",
        "                add_edge(idx, body_idx, \"CFG_LOOP\")\n",
        "\n",
        "    last_def = {}\n",
        "\n",
        "    def extract_assigned_name(raw_node) -> str | None:\n",
        "        target = getattr(raw_node, \"expressionl\", None) or getattr(raw_node, \"left\", None)\n",
        "        if target is None:\n",
        "            return None\n",
        "        if hasattr(target, \"member\") and target.member:\n",
        "            return str(target.member)\n",
        "        if hasattr(target, \"name\") and target.name:\n",
        "            return str(target.name)\n",
        "        return None\n",
        "\n",
        "    for idx, node in enumerate(nodes):\n",
        "        node_type = node[\"node_type\"]\n",
        "        label = node[\"label\"]\n",
        "        raw = node[\"raw\"]\n",
        "\n",
        "        if node_type in {\"VariableDeclarator\", \"FormalParameter\"} and label:\n",
        "            last_def[label] = idx\n",
        "\n",
        "        if node_type == \"Assignment\":\n",
        "            assigned = extract_assigned_name(raw)\n",
        "            if assigned:\n",
        "                last_def[assigned] = idx\n",
        "\n",
        "        if node_type == \"MemberReference\" and label:\n",
        "            if label in last_def:\n",
        "                def_idx = last_def[label]\n",
        "                add_edge(def_idx, idx, \"DEF_USE\")\n",
        "                add_edge(idx, def_idx, \"USE_DEF\")\n",
        "\n",
        "    return nodes, parents, children, edges, edge_types\n",
        "\n",
        "\n",
        "def match_actions_to_nodes(code: str, nodes: list[dict], parents: list[int | None], actions):\n",
        "    action_map: dict[int, EditType] = {}\n",
        "\n",
        "    for action in actions:\n",
        "        node_type = action.node.node_type\n",
        "        label = action.node.label\n",
        "        pos = action.node.position\n",
        "        line = None\n",
        "        col = None\n",
        "        if pos is not None:\n",
        "            line, col = offset_to_line_col(code, pos[0])\n",
        "\n",
        "        candidates = [i for i, n in enumerate(nodes) if n[\"node_type\"] == node_type]\n",
        "        if label:\n",
        "            label_candidates = [i for i in candidates if nodes[i][\"label\"] == label]\n",
        "            if label_candidates:\n",
        "                candidates = label_candidates\n",
        "        if line:\n",
        "            line_candidates = [i for i in candidates if nodes[i][\"line\"] == line]\n",
        "            if line_candidates:\n",
        "                candidates = line_candidates\n",
        "\n",
        "        if not candidates:\n",
        "            continue\n",
        "\n",
        "        if col is not None:\n",
        "            candidates.sort(key=lambda i: abs((nodes[i][\"col\"] or col) - col))\n",
        "\n",
        "        matched_idx = candidates[0]\n",
        "        action_map[matched_idx] = action.action_type\n",
        "\n",
        "    subtree_changed = [0] * len(nodes)\n",
        "    for idx in action_map.keys():\n",
        "        cur = parents[idx]\n",
        "        while cur is not None:\n",
        "            subtree_changed[cur] = 1\n",
        "            cur = parents[cur]\n",
        "\n",
        "    return action_map, subtree_changed\n",
        "\n",
        "\n",
        "def build_diff_features(action_map: dict[int, EditType], subtree_changed: list[int], num_nodes: int):\n",
        "    diff_feats = []\n",
        "    labels = []\n",
        "    for idx in range(num_nodes):\n",
        "        action = action_map.get(idx)\n",
        "        is_diff = 1 if action is not None else 0\n",
        "        action_none = 1 if action is None else 0\n",
        "        action_update = 1 if action == EditType.UPDATE else 0\n",
        "        action_delete = 1 if action == EditType.DELETE else 0\n",
        "        action_move = 1 if action == EditType.MOVE else 0\n",
        "        diff_feats.append([\n",
        "            is_diff,\n",
        "            action_none,\n",
        "            action_update,\n",
        "            action_delete,\n",
        "            action_move,\n",
        "            subtree_changed[idx],\n",
        "        ])\n",
        "        labels.append(1 if action in {EditType.UPDATE, EditType.DELETE} else 0)\n",
        "    return torch.tensor(diff_feats, dtype=torch.float), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "\n",
        "def add_diff_edges(children, parents, action_map, edges, edge_types):\n",
        "    changed_nodes = set(action_map.keys())\n",
        "    for idx in changed_nodes:\n",
        "        parent = parents[idx]\n",
        "        if parent is not None:\n",
        "            edges.append((idx, parent))\n",
        "            edge_types.append(RELATION_TO_ID[\"DIFF_PARENT\"])\n",
        "            for sibling in children[parent]:\n",
        "                if sibling == idx:\n",
        "                    continue\n",
        "                edges.append((idx, sibling))\n",
        "                edge_types.append(RELATION_TO_ID[\"DIFF_SIBLING\"])\n",
        "                edges.append((sibling, idx))\n",
        "                edge_types.append(RELATION_TO_ID[\"DIFF_SIBLING\"])\n",
        "\n",
        "\n",
        "def get_node_type_id(node_type: str) -> int:\n",
        "    return node_type_to_id.get(node_type, node_type_to_id[\"UNK\"])\n",
        "\n",
        "\n",
        "def compute_code_embeddings(code: str, nodes: list[dict], children: list[list[int]]):\n",
        "    enc = tokenizer(\n",
        "        code,\n",
        "        return_tensors=\"pt\",\n",
        "        return_offsets_mapping=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "    )\n",
        "    offsets = enc.pop(\"offset_mapping\")[0].tolist()\n",
        "    enc = {k: v.to(DEVICE) for k, v in enc.items()}\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = encoder(**enc)\n",
        "    token_embs = outputs.last_hidden_state[0].cpu()\n",
        "\n",
        "    num_nodes = len(nodes)\n",
        "    node_embs = torch.zeros((num_nodes, token_embs.shape[-1]), dtype=torch.float)\n",
        "\n",
        "    for idx, node in enumerate(nodes):\n",
        "        start = node[\"start_pos\"]\n",
        "        end = node[\"end_pos\"]\n",
        "        if start is None or end is None or start == end:\n",
        "            continue\n",
        "        token_idxs = [\n",
        "            t for t, (s, e) in enumerate(offsets)\n",
        "            if not (s == 0 and e == 0) and s < end and e > start\n",
        "        ]\n",
        "        if token_idxs:\n",
        "            node_embs[idx] = token_embs[token_idxs].mean(dim=0)\n",
        "\n",
        "    for idx in reversed(range(num_nodes)):\n",
        "        if torch.all(node_embs[idx] == 0) and children[idx]:\n",
        "            child_embs = [node_embs[c] for c in children[idx] if torch.any(node_embs[c] != 0)]\n",
        "            if child_embs:\n",
        "                node_embs[idx] = torch.stack(child_embs).mean(dim=0)\n",
        "\n",
        "    return node_embs\n",
        "\n",
        "\n",
        "def build_graph_parts(buggy_code: str, fixed_code: str, method_id: str):\n",
        "    nodes, parents, children, edges, edge_types = build_ast_graph(buggy_code)\n",
        "\n",
        "    diff_result = gumtree_diff.diff(buggy_code, fixed_code)\n",
        "    action_map, subtree_changed = match_actions_to_nodes(buggy_code, nodes, parents, diff_result.actions)\n",
        "\n",
        "    diff_feats, labels = build_diff_features(action_map, subtree_changed, len(nodes))\n",
        "    add_diff_edges(children, parents, action_map, edges, edge_types)\n",
        "\n",
        "    node_type_ids = torch.tensor([get_node_type_id(n[\"node_type\"]) for n in nodes], dtype=torch.long)\n",
        "\n",
        "    return {\n",
        "        \"buggy_code\": buggy_code,\n",
        "        \"nodes\": nodes,\n",
        "        \"parents\": parents,\n",
        "        \"children\": children,\n",
        "        \"edges\": edges,\n",
        "        \"edge_types\": edge_types,\n",
        "        \"diff_feats\": diff_feats,\n",
        "        \"labels\": labels,\n",
        "        \"node_type_ids\": node_type_ids,\n",
        "        \"method_id\": method_id,\n",
        "    }\n",
        "\n",
        "\n",
        "def build_graph_sample(\n",
        "    buggy_code: str,\n",
        "    fixed_code: str,\n",
        "    method_id: str,\n",
        "):\n",
        "    parts = build_graph_parts(buggy_code, fixed_code, method_id)\n",
        "\n",
        "    code_embs = compute_code_embeddings(\n",
        "        parts[\"buggy_code\"], parts[\"nodes\"], parts[\"children\"]\n",
        "    )\n",
        "\n",
        "    x = torch.cat([code_embs, parts[\"diff_feats\"]], dim=1)\n",
        "\n",
        "    if parts[\"edges\"]:\n",
        "        edge_index = torch.tensor(parts[\"edges\"], dtype=torch.long).t().contiguous()\n",
        "        edge_type = torch.tensor(parts[\"edge_types\"], dtype=torch.long)\n",
        "    else:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_type = torch.empty((0,), dtype=torch.long)\n",
        "\n",
        "    data = Data(\n",
        "        x=x,\n",
        "        edge_index=edge_index,\n",
        "        edge_type=edge_type,\n",
        "        y=parts[\"labels\"],\n",
        "        node_type_ids=parts[\"node_type_ids\"],\n",
        "        method_id=parts[\"method_id\"],\n",
        "    )\n",
        "    return data, parts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "b73e0d28",
      "metadata": {},
      "outputs": [],
      "source": [
        "HUNK_RE = re.compile(r\"^@@ -(\\d+)(?:,(\\d+))? \\+(\\d+)(?:,(\\d+))? @@\")\n",
        "\n",
        "\n",
        "def _find_sublist(haystack: list[str], needle: list[str], start: int = 0) -> int | None:\n",
        "    if not needle:\n",
        "        return start\n",
        "    max_i = len(haystack) - len(needle)\n",
        "    for i in range(start, max_i + 1):\n",
        "        if haystack[i : i + len(needle)] == needle:\n",
        "            return i\n",
        "    return None\n",
        "\n",
        "\n",
        "def apply_unified_diff(source: str, diff_text: str) -> str:\n",
        "    src_lines = source.splitlines()\n",
        "    result = []\n",
        "    src_pos = 0\n",
        "\n",
        "    lines = diff_text.splitlines()\n",
        "    i = 0\n",
        "    while i < len(lines):\n",
        "        line = lines[i]\n",
        "        if not line.startswith(\"@@\"):\n",
        "            i += 1\n",
        "            continue\n",
        "\n",
        "        m = HUNK_RE.match(line)\n",
        "        if not m:\n",
        "            raise ValueError(f\"Invalid hunk header: {line}\")\n",
        "        src_start = int(m.group(1)) - 1\n",
        "\n",
        "        i += 1\n",
        "        hunk_lines = []\n",
        "        while i < len(lines) and not lines[i].startswith(\"@@\"):\n",
        "            hline = lines[i]\n",
        "            if hline.startswith((\"---\", \"+++\", \"diff \", \"index \")):\n",
        "                i += 1\n",
        "                continue\n",
        "            if hline == \"\":\n",
        "                i += 1\n",
        "                continue\n",
        "            if hline[0] not in {\" \", \"-\", \"+\", \"\\\\\"}:\n",
        "                raise ValueError(f\"Unexpected diff line: {hline}\")\n",
        "            hunk_lines.append(hline)\n",
        "            i += 1\n",
        "\n",
        "        before_lines = [h[1:] for h in hunk_lines if h.startswith((\" \", \"-\"))]\n",
        "        found = _find_sublist(src_lines, before_lines, start=src_pos)\n",
        "        if found is None:\n",
        "            found = src_start\n",
        "        if found < src_pos:\n",
        "            raise ValueError(\"Hunk overlaps previous content\")\n",
        "\n",
        "        result.extend(src_lines[src_pos:found])\n",
        "        src_pos = found\n",
        "\n",
        "        for hline in hunk_lines:\n",
        "            if hline.startswith(\" \"):\n",
        "                result.append(src_lines[src_pos])\n",
        "                src_pos += 1\n",
        "            elif hline.startswith(\"-\"):\n",
        "                src_pos += 1\n",
        "            elif hline.startswith(\"+\"):\n",
        "                result.append(hline[1:])\n",
        "            elif hline.startswith(\"\\\\\"):\n",
        "                pass\n",
        "\n",
        "    result.extend(src_lines[src_pos:])\n",
        "    fixed = \"\\n\".join(result)\n",
        "    if source.endswith(\"\\n\"):\n",
        "        fixed += \"\\n\"\n",
        "    return fixed"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce0fd418",
      "metadata": {},
      "source": [
        "# Infer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9259a4ea",
      "metadata": {},
      "outputs": [],
      "source": [
        "# BUGGY_CODE = \"\"\"\n",
        "# public int sum(int[] arr) {\n",
        "#     int s = 0;\n",
        "#     for (int i = 0; i <= arr.length; i++) {\n",
        "#         s += arr[i];\n",
        "#     }\n",
        "#     return s;\n",
        "# }\n",
        "# \"\"\".strip()\n",
        "\n",
        "# DIFF_TEXT = \"\"\"\n",
        "# --- a/Snippet.java\n",
        "# +++ b/Snippet.java\n",
        "# @@ -2,7 +2,7 @@\n",
        "#  public int sum(int[] arr) {\n",
        "#      int s = 0;\n",
        "# -    for (int i = 0; i <= arr.length; i++) {\n",
        "# +    for (int i = 0; i < arr.length; i++) {\n",
        "#          s += arr[i];\n",
        "#      }\n",
        "#      return s;\n",
        "# \"\"\".strip()\n",
        "# FIXED_CODE = \"\"\"\"\"\".strip()\n",
        "\n",
        "# if DIFF_TEXT:\n",
        "#     fixed_code = apply_unified_diff(BUGGY_CODE, DIFF_TEXT)\n",
        "# else:\n",
        "#     fixed_code = FIXED_CODE if FIXED_CODE else BUGGY_CODE\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "5a882d73",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df=pd.read_csv('megadiff_single_function_100.csv')\n",
        "buggy_funcs = df['buggy_function']\n",
        "fixed_funcs = df['fixed_function']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "afd56ec1",
      "metadata": {},
      "outputs": [],
      "source": [
        "def infer():\n",
        "    data, parts = build_graph_sample(\n",
        "        BUGGY_CODE,\n",
        "        FIXED_CODE,\n",
        "        method_id=\"manual\",\n",
        "    )\n",
        "\n",
        "    loader = DataLoader([data], batch_size=1)\n",
        "    batch = next(iter(loader)).to(DEVICE)\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        node_logits, graph_logits = model(batch)\n",
        "\n",
        "    node_probs = torch.sigmoid(node_logits).detach().cpu().numpy()\n",
        "    graph_prob = float(torch.sigmoid(graph_logits).item())\n",
        "    if graph_prob < 0.5:\n",
        "        return\n",
        "    print(f\"Graph bug probability: {graph_prob:.4f}\")\n",
        "\n",
        "    # Node Inference\n",
        "    TOP_K = 10\n",
        "\n",
        "    nodes = parts[\"nodes\"]\n",
        "    lines = BUGGY_CODE.splitlines()\n",
        "\n",
        "    ranked = sorted(range(len(node_probs)), key=lambda i: node_probs[i], reverse=True)\n",
        "    print(\"Top node predictions:\")\n",
        "\n",
        "    for rank, idx in enumerate(ranked[:TOP_K], 1):\n",
        "        node = nodes[idx]\n",
        "        line = node.get(\"line\")\n",
        "        col = node.get(\"col\")\n",
        "        label = node.get(\"label\") or \"\"\n",
        "        node_type = node.get(\"node_type\")\n",
        "        prob = float(node_probs[idx])\n",
        "\n",
        "        line_text = \"\"\n",
        "        if line is not None and 1 <= line <= len(lines):\n",
        "            line_text = lines[line - 1].strip()\n",
        "\n",
        "        if prob < 0.2:\n",
        "            return\n",
        "        print(\n",
        "            f\"{rank:02d}. prob={prob:.4f} type={node_type} label={label} line={line} col={col} | {line_text}\"\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "85c58b03",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "800\n",
            "801\n",
            "802\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "01. prob=1.0000 type=ReturnStatement label= line=21 col=17 | \n",
            "02. prob=1.0000 type=MethodInvocation label=floor line=12 col=36 | final double lonMinFloor = Math.floor(lonMin);\n",
            "803\n",
            "804\n",
            "805\n",
            "806\n",
            "807\n",
            "808\n",
            "809\n",
            "810\n",
            "811\n",
            "812\n",
            "813\n",
            "814\n",
            "815\n",
            "816\n",
            "817\n",
            "818\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "01. prob=0.9901 type=BreakStatement label= line=41 col=9 | case CLOSE:\n",
            "819\n",
            "820\n",
            "821\n",
            "822\n",
            "823\n",
            "824\n",
            "825\n",
            "826\n",
            "827\n",
            "828\n",
            "829\n",
            "830\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "831\n",
            "832\n",
            "833\n",
            "834\n",
            "835\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "836\n",
            "837\n",
            "838\n",
            "839\n",
            "Graph bug probability: 0.9979\n",
            "Top node predictions:\n",
            "01. prob=1.0000 type=Assignment label=Literal(postfix_operators=[], prefix_operators=[], qualifier=None, selectors=[], value=null) line=None col=None | \n",
            "02. prob=0.3495 type=MethodInvocation label=substring line=141 col=37 | break;\n",
            "840\n",
            "841\n",
            "842\n",
            "843\n",
            "844\n",
            "845\n",
            "846\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "01. prob=1.0000 type=MethodInvocation label=get line=56 col=52 | timeList.add(QlockLanguage.UHR);\n",
            "847\n",
            "848\n",
            "849\n",
            "Graph bug probability: 0.9999\n",
            "Top node predictions:\n",
            "850\n",
            "851\n",
            "852\n",
            "853\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "854\n",
            "855\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "856\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "857\n",
            "858\n",
            "859\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "860\n",
            "861\n",
            "862\n",
            "863\n",
            "Graph bug probability: 0.9786\n",
            "Top node predictions:\n",
            "864\n",
            "865\n",
            "866\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "867\n",
            "868\n",
            "869\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "870\n",
            "871\n",
            "872\n",
            "873\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "874\n",
            "875\n",
            "876\n",
            "877\n",
            "878\n",
            "879\n",
            "880\n",
            "881\n",
            "882\n",
            "883\n",
            "884\n",
            "885\n",
            "886\n",
            "887\n",
            "888\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "01. prob=1.0000 type=MethodInvocation label=query line=38 col=29 | assertFalse(repoCollector.isEmpty());\n",
            "02. prob=1.0000 type=MethodInvocation label=toURI line=42 col=31 | assertTrue(manager.contains(defaultAgenRepositoryDirectory.toURI()));\n",
            "889\n",
            "890\n",
            "891\n",
            "892\n",
            "893\n",
            "894\n",
            "895\n",
            "Graph bug probability: 1.0000\n",
            "Top node predictions:\n",
            "896\n",
            "897\n",
            "898\n",
            "899\n",
            "900\n",
            "901\n",
            "902\n",
            "903\n",
            "904\n",
            "905\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m BUGGY_CODE = buggy_funcs[index]\n\u001b[32m      4\u001b[39m FIXED_CODE = fixed_funcs[index]\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36minfer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minfer\u001b[39m():\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     data, parts = \u001b[43mbuild_graph_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mBUGGY_CODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mFIXED_CODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmanual\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m     loader = DataLoader([data], batch_size=\u001b[32m1\u001b[39m)\n\u001b[32m      9\u001b[39m     batch = \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(loader)).to(DEVICE)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 367\u001b[39m, in \u001b[36mbuild_graph_sample\u001b[39m\u001b[34m(buggy_code, fixed_code, method_id)\u001b[39m\n\u001b[32m    360\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbuild_graph_sample\u001b[39m(\n\u001b[32m    361\u001b[39m     buggy_code: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    362\u001b[39m     fixed_code: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    363\u001b[39m     method_id: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    364\u001b[39m ):\n\u001b[32m    365\u001b[39m     parts = build_graph_parts(buggy_code, fixed_code, method_id)\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     code_embs = \u001b[43mcompute_code_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparts\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mbuggy_code\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparts\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnodes\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparts\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchildren\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    371\u001b[39m     x = torch.cat([code_embs, parts[\u001b[33m\"\u001b[39m\u001b[33mdiff_feats\u001b[39m\u001b[33m\"\u001b[39m]], dim=\u001b[32m1\u001b[39m)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m parts[\u001b[33m\"\u001b[39m\u001b[33medges\u001b[39m\u001b[33m\"\u001b[39m]:\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 308\u001b[39m, in \u001b[36mcompute_code_embeddings\u001b[39m\u001b[34m(code, nodes, children)\u001b[39m\n\u001b[32m    305\u001b[39m enc = {k: v.to(DEVICE) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m enc.items()}\n\u001b[32m    307\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.inference_mode():\n\u001b[32m--> \u001b[39m\u001b[32m308\u001b[39m     outputs = \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43menc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    309\u001b[39m token_embs = outputs.last_hidden_state[\u001b[32m0\u001b[39m].cpu()\n\u001b[32m    311\u001b[39m num_nodes = \u001b[38;5;28mlen\u001b[39m(nodes)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:862\u001b[39m, in \u001b[36mRobertaModel.forward\u001b[39m\u001b[34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    855\u001b[39m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[32m    856\u001b[39m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[32m    857\u001b[39m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[32m    858\u001b[39m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[32m    859\u001b[39m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[32m    860\u001b[39m head_mask = \u001b[38;5;28mself\u001b[39m.get_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m.config.num_hidden_layers)\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m encoder_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    865\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    866\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    867\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    875\u001b[39m sequence_output = encoder_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    876\u001b[39m pooled_output = \u001b[38;5;28mself\u001b[39m.pooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.pooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:606\u001b[39m, in \u001b[36mRobertaEncoder.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[39m\n\u001b[32m    602\u001b[39m     all_hidden_states = all_hidden_states + (hidden_states,)\n\u001b[32m    604\u001b[39m layer_head_mask = head_mask[i] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m606\u001b[39m layer_outputs = \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    608\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    609\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    610\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# as a positional argument for gradient checkpointing\u001b[39;49;00m\n\u001b[32m    611\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    612\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    613\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    614\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    615\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    617\u001b[39m hidden_states = layer_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/transformers/modeling_layers.py:94\u001b[39m, in \u001b[36mGradientCheckpointingLayer.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     91\u001b[39m         logger.warning_once(message)\n\u001b[32m     93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._gradient_checkpointing_func(partial(\u001b[38;5;28msuper\u001b[39m().\u001b[34m__call__\u001b[39m, **kwargs), *args)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/transformers/utils/deprecation.py:172\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>.wrapper.<locals>.wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m minimum_action \u001b[38;5;129;01min\u001b[39;00m (Action.NOTIFY, Action.NOTIFY_ALWAYS) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torchdynamo_compiling():\n\u001b[32m    169\u001b[39m     \u001b[38;5;66;03m# DeprecationWarning is ignored by default, so we use FutureWarning instead\u001b[39;00m\n\u001b[32m    170\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m172\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:543\u001b[39m, in \u001b[36mRobertaLayer.forward\u001b[39m\u001b[34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, output_attentions, cache_position)\u001b[39m\n\u001b[32m    540\u001b[39m     attention_output = cross_attention_outputs[\u001b[32m0\u001b[39m]\n\u001b[32m    541\u001b[39m     outputs = outputs + cross_attention_outputs[\u001b[32m1\u001b[39m:]  \u001b[38;5;66;03m# add cross attentions if we output attention weights\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m543\u001b[39m layer_output = \u001b[43mapply_chunking_to_forward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    544\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfeed_forward_chunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mchunk_size_feed_forward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mseq_len_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_output\u001b[49m\n\u001b[32m    545\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    546\u001b[39m outputs = (layer_output,) + outputs\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/transformers/pytorch_utils.py:257\u001b[39m, in \u001b[36mapply_chunking_to_forward\u001b[39m\u001b[34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[39m\n\u001b[32m    254\u001b[39m     \u001b[38;5;66;03m# concatenate output at same dimension\u001b[39;00m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.cat(output_chunks, dim=chunk_dim)\n\u001b[32m--> \u001b[39m\u001b[32m257\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43minput_tensors\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:551\u001b[39m, in \u001b[36mRobertaLayer.feed_forward_chunk\u001b[39m\u001b[34m(self, attention_output)\u001b[39m\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeed_forward_chunk\u001b[39m(\u001b[38;5;28mself\u001b[39m, attention_output):\n\u001b[32m--> \u001b[39m\u001b[32m551\u001b[39m     intermediate_output = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mintermediate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattention_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    552\u001b[39m     layer_output = \u001b[38;5;28mself\u001b[39m.output(intermediate_output, attention_output)\n\u001b[32m    553\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m layer_output\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/transformers/models/roberta/modeling_roberta.py:465\u001b[39m, in \u001b[36mRobertaIntermediate.forward\u001b[39m\u001b[34m(self, hidden_states)\u001b[39m\n\u001b[32m    464\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch.Tensor) -> torch.Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m465\u001b[39m     hidden_states = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdense\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    466\u001b[39m     hidden_states = \u001b[38;5;28mself\u001b[39m.intermediate_act_fn(hidden_states)\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/dacn/untitled folder/.venv/lib/python3.12/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "for index in [62, 92, 179, 186, 839, 846, 888]:\n",
        "    print(index)\n",
        "    BUGGY_CODE = buggy_funcs[index]\n",
        "    FIXED_CODE = fixed_funcs[index]\n",
        "    infer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3aa7141d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(125, 146, 177, 173, 179, 186)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "802 808 818 839 846 888"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ac3fa10f",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(62, 92)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "62, 92, 179, 186, 839, 846, 888"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "9a070808",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph bug probability: 0.9976\n",
            "Top node predictions:\n",
            "01. prob=1.0000 type=MethodInvocation label=getAbsolutePath line=25 col=47 | when(project.getBuild()).thenReturn(build);\n"
          ]
        }
      ],
      "source": [
        "index = 62\n",
        "BUGGY_CODE = buggy_funcs[index]\n",
        "FIXED_CODE = fixed_funcs[index]\n",
        "\n",
        "BUGGY_CODE\n",
        "infer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "6540c7b2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- \n",
            "+++ \n",
            "@@ -1,4 +1,4 @@\n",
            "-\tpublic void testDefaultAgentRepoAndBundlePoolFromProfileRepo() {\n",
            "+\tpublic void testDefaultAgentRepoAndBundlePoolFromProfileRepo() throws InterruptedException {\n",
            " \t\tFile testData = getTestData(\"0.1\", \"testData/sdkpatchingtest\");\n",
            " \t\t// /p2/org.eclipse.equinox.p2.engine/profileRegistry\");\n",
            " \t\tFile tempFolder = getTempFolder();\n",
            "@@ -38,6 +38,13 @@\n",
            " \t\tassertFalse(repoCollector.isEmpty());\n",
            " \t\tassertTrue(repoCollector.toCollection().containsAll(profileCollector.toCollection()));\n",
            " \n",
            "-\t\tassertTrue(manager.contains(tempFolder.toURI()));\n",
            "-\t\tassertTrue(manager.contains(defaultAgenRepositoryDirectory.toURI()));\n",
            "+\t\tint maxTries = 20;\n",
            "+\t\tint current = 0;\n",
            "+\t\twhile (true) {\n",
            "+\t\t\tif (manager.contains(tempFolder.toURI()) && manager.contains(defaultAgenRepositoryDirectory.toURI()))\n",
            "+\t\t\t\tbreak;\n",
            "+\t\t\tif (++current == maxTries)\n",
            "+\t\t\t\tfail(\"profile artifact repos not added\");\n",
            "+\t\t\tThread.sleep(100);\n",
            "+\t\t}\n",
            " \t}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import difflib \n",
        "\n",
        "diff_output = list(difflib.unified_diff(\n",
        "    BUGGY_CODE.splitlines(keepends=True), \n",
        "    FIXED_CODE.splitlines(keepends=True),\n",
        "))\n",
        "print(''.join(diff_output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "bfd05e2b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    public void setup(){\n",
            "        //Create the temp dir\n",
            "        final File sysTempDir = new File(System.getProperty(\"java.io.tmpdir\"));\n",
            "        String dirName = UUID.randomUUID().toString();\n",
            "        tempDir = new File(sysTempDir, dirName);\n",
            "        productDir = new File(tempDir,PROJECT_ID);\n",
            "        tempResourcesDir = new File(productDir,TMP_RESOURCES);\n",
            "        generatedHomeDir = new File(tempResourcesDir,GENERATED_HOME);\n",
            "        pluginsDir = new File(generatedHomeDir,PLUGINS);\n",
            "        bundledPluginsDir = new File(generatedHomeDir,BUNDLED_PLUGINS);\n",
            "\n",
            "        //setup maven mocks\n",
            "        MavenProject project = mock(MavenProject.class);\n",
            "        Build build = mock(Build.class);\n",
            "\n",
            "        //Mockito throws NoClassDefFoundError: org/apache/maven/project/ProjectBuilderConfiguration\n",
            "        //when mocking the session\n",
            "        //MavenSession session = mock(MavenSession.class);\n",
            "\n",
            "        PluginManager pluginManager = mock(PluginManager.class);\n",
            "        List<MavenProject> reactor = Collections.<MavenProject>emptyList();\n",
            "        ctx = mock(MavenContext.class);\n",
            "\n",
            "        when(build.getDirectory()).thenReturn(tempDir.getAbsolutePath());\n",
            "        when(project.getBuild()).thenReturn(build);\n",
            "        when(ctx.getProject()).thenReturn(project);\n",
            "        when(ctx.getLog()).thenReturn(new SystemStreamLog());\n",
            "        when(ctx.getReactor()).thenReturn(reactor);\n",
            "        when(ctx.getSession()).thenReturn(null);\n",
            "        when(ctx.getPluginManager()).thenReturn(pluginManager);\n",
            "\n",
            "        goals = new MavenGoals(ctx);\n",
            "    }\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(BUGGY_CODE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8cf83b61",
      "metadata": {},
      "source": [
        "# Visual"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "0c5266ba",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- buggy\n",
            "+++ fixed\n",
            "@@ -7,13 +7,13 @@\n",
            "         boolean isBetter = false;\n",
            "         switch (policy) {\n",
            "             case MINIMIZE:\n",
            "-                if (bestVal > val) {\n",
            "+                if (bestVal > val || nbSol==1) {\n",
            "                     bestVal = val;\n",
            "                     isBetter = true;\n",
            "                 }\n",
            "                 break;\n",
            "             case MAXIMIZE:\n",
            "-                if (bestVal < val) {\n",
            "+                if (bestVal < val || nbSol==1) {\n",
            "                     bestVal = val;\n",
            "                     isBetter = true;\n",
            "                 }\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import difflib\n",
        "\n",
        "diff_output = list(difflib.unified_diff(\n",
        "    BUGGY_CODE.splitlines(keepends=True),\n",
        "    FIXED_CODE.splitlines(keepends=True),\n",
        "    fromfile='buggy',\n",
        "    tofile='fixed'\n",
        "))\n",
        "print(''.join(diff_output))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "fd33560c",
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'utils.feature_extractor'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfeature_extractor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DiffFeatureExtractor\n\u001b[32m      2\u001b[39m extractor = DiffFeatureExtractor(gumtree_path=\u001b[33m'\u001b[39m\u001b[33m./gumtree-4.0.0-beta4/bin/gumtree\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m features = extractor.extract(BUGGY_CODE, FIXED_CODE)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utils.feature_extractor'"
          ]
        }
      ],
      "source": [
        "from utils.feature_extractor import DiffFeatureExtractor\n",
        "extractor = DiffFeatureExtractor(gumtree_path='./gumtree-4.0.0-beta4/bin/gumtree')\n",
        "features = extractor.extract(BUGGY_CODE, FIXED_CODE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4ee7799",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Step 4: Visualize buggy regions\n",
        "from IPython.display import HTML\n",
        "\n",
        "def visualize_buggy_code(code: str, line_mask: dict) -> str:\n",
        "    \"\"\"Highlight buggy lines in HTML\"\"\"\n",
        "    lines = code.split('\\n')\n",
        "    html_lines = []\n",
        "    \n",
        "    for i, line in enumerate(lines, 1):\n",
        "        is_buggy = line_mask.get(i, 0) == 1\n",
        "        escaped_line = line.replace('<', '&lt;').replace('>', '&gt;')\n",
        "        \n",
        "        if is_buggy:\n",
        "            html_lines.append(f'<span style=\"background-color: #ffcccc; display: block;\">{i:3d} |  {escaped_line}</span>')\n",
        "        else:\n",
        "            html_lines.append(f'<span style=\"display: block;\">{i:3d} |    {escaped_line}</span>')\n",
        "    \n",
        "    return f'<pre style=\"font-family: monospace; font-size: 12px; background: #f5f5f5; padding: 10px; border-radius: 5px;\">{\"\".join(html_lines)}</pre>'\n",
        "\n",
        "# Display buggy code with highlights\n",
        "html_output = visualize_buggy_code(BUGGY_CODE, features.mask.line_mask)\n",
        "HTML(html_output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8b8fa85d",
      "metadata": {},
      "source": [
        "# Plot hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02829542",
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "hist = torch.load('output/train_hist.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43a90da4",
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "epochs = [item[\"epoch\"] for item in hist]\n",
        "train_loss = [item[\"train_loss\"] for item in hist]\n",
        "val_loss = [item[\"val_loss\"] for item in hist]\n",
        "\n",
        "train_node = np.array([item[\"train_node\"] for item in hist])\n",
        "val_node = np.array([item[\"val_node\"] for item in hist])\n",
        "train_graph = np.array([item[\"train_graph\"] for item in hist])\n",
        "val_graph = np.array([item[\"val_graph\"] for item in hist])\n",
        "\n",
        "fig, axes = plt.subplots(3, 1, figsize=(12, 12), sharex=True)\n",
        "\n",
        "axes[0].plot(epochs, train_loss, label=\"train_loss\")\n",
        "axes[0].plot(epochs, val_loss, label=\"val_loss\")\n",
        "axes[0].set_ylabel(\"Loss\")\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "axes[0].legend()\n",
        "\n",
        "metrics = ['pre', 'rec', 'f1', 'acc']\n",
        "for i in range(train_node.shape[1]):\n",
        "    axes[1].plot(epochs, train_node[:, i], label=f\"train_node_{metrics[i]}\")\n",
        "    axes[1].plot(epochs, val_node[:, i], linestyle=\"--\", label=f\"val_node_{metrics[i]}\")\n",
        "axes[1].set_ylabel(\"Node metrics\")\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "axes[1].legend(ncol=2, fontsize=9)\n",
        "\n",
        "for i in range(train_graph.shape[1]):\n",
        "    axes[2].plot(epochs, train_graph[:, i], label=f\"train_graph_{metrics[i]}\")\n",
        "    axes[2].plot(epochs, val_graph[:, i], linestyle=\"--\", label=f\"val_graph_{metrics[i]}\")\n",
        "axes[2].set_ylabel(\"Graph metrics\")\n",
        "axes[2].set_xlabel(\"Epoch\")\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "axes[2].legend(ncol=2, fontsize=9)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "502fe190",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
