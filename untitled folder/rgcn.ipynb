{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7b23f002",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import javalang\n",
        "import multiprocessing as mp\n",
        "\n",
        "# Avoid tokenizers fork warning by fixing parallelism behavior early.\n",
        "os.environ.setdefault(\"TOKENIZERS_PARALLELISM\", \"false\")\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "sys.path.insert(0, \"E:/CodeBuggy\")\n",
        "\n",
        "from pipeline.gumtree_diff import GumTreeDiff, EditType\n",
        "\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import RGCNConv, global_mean_pool\n",
        "\n",
        "\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "f966aecb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 71150 valid samples\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>diff</th>\n",
              "      <th>buggy_function</th>\n",
              "      <th>fixed_function</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>diff --git a/src/main/java/hudson/remoting/Pin...</td>\n",
              "      <td>private void ping() throws IOException, In...</td>\n",
              "      <td>private void ping() throws IOException, In...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>diff --git a/choco-parser/src/main/java/parser...</td>\n",
              "      <td>public synchronized boolean newSol(int val...</td>\n",
              "      <td>public synchronized boolean newSol(int val...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>diff --git a/opentripplanner-routing/src/main/...</td>\n",
              "      <td>public State traverse(State s0) {\\n       ...</td>\n",
              "      <td>public State traverse(State s0) {\\n       ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>diff --git a/src/java/davmail/ldap/LdapConnect...</td>\n",
              "      <td>public void run() {\\n            try {...</td>\n",
              "      <td>public void run() {\\n            try {...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>diff --git a/src/com/orangeleap/tangerine/web/...</td>\n",
              "      <td>public void addListFieldsToMap(HttpServlet...</td>\n",
              "      <td>public void addListFieldsToMap(HttpServlet...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                diff  \\\n",
              "0  diff --git a/src/main/java/hudson/remoting/Pin...   \n",
              "1  diff --git a/choco-parser/src/main/java/parser...   \n",
              "2  diff --git a/opentripplanner-routing/src/main/...   \n",
              "3  diff --git a/src/java/davmail/ldap/LdapConnect...   \n",
              "4  diff --git a/src/com/orangeleap/tangerine/web/...   \n",
              "\n",
              "                                      buggy_function  \\\n",
              "0      private void ping() throws IOException, In...   \n",
              "1      public synchronized boolean newSol(int val...   \n",
              "2      public State traverse(State s0) {\\n       ...   \n",
              "3          public void run() {\\n            try {...   \n",
              "4      public void addListFieldsToMap(HttpServlet...   \n",
              "\n",
              "                                      fixed_function  \n",
              "0      private void ping() throws IOException, In...  \n",
              "1      public synchronized boolean newSol(int val...  \n",
              "2      public State traverse(State s0) {\\n       ...  \n",
              "3          public void run() {\\n            try {...  \n",
              "4      public void addListFieldsToMap(HttpServlet...  "
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "DATA_PATH = \"inputs/megadiff_single_function.parquet\"\n",
        "GUMTREE_PATH = \"E:/CodeBuggy/gumtree-4.0.0-beta4/bin/gumtree.bat\"\n",
        "MODEL_NAME = \"microsoft/graphcodebert-base\"\n",
        "OUTPUT_DIR = \"output/rgcn_graphs\"\n",
        "MAX_SAMPLES = min(71150, 71150) # 71150 is num of samples\n",
        "USE_CODE_EMBEDDINGS = True\n",
        "NODE_TYPE_EMB_DIM = 64\n",
        "DIFF_FEATURE_DIM = 6\n",
        "LABEL_PARENTS = False\n",
        "\n",
        "EMB_BATCH_SIZE = 8\n",
        "SAVE_CHUNK_SIZE = 10000\n",
        "USE_MULTIPROCESSING = True\n",
        "NUM_WORKERS = max(1, (os.cpu_count() or 2) - 1)\n",
        "MP_CHUNKSIZE = 8\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
        "\n",
        "df = pd.read_parquet(DATA_PATH)\n",
        "\n",
        "print(f\"Loaded {len(df)} valid samples\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a277b84b",
      "metadata": {},
      "outputs": [],
      "source": [
        "RELATIONS = [\n",
        "    \"AST_CHILD\",\n",
        "    \"AST_PARENT\",\n",
        "    \"CFG_NEXT\",\n",
        "    \"CFG_TRUE\",\n",
        "    \"CFG_FALSE\",\n",
        "    \"CFG_LOOP\",\n",
        "    \"DEF_USE\",\n",
        "    \"USE_DEF\",\n",
        "    \"DIFF_PARENT\",\n",
        "    \"DIFF_SIBLING\",\n",
        "]\n",
        "RELATION_TO_ID = {r: i for i, r in enumerate(RELATIONS)}\n",
        "\n",
        "STATEMENT_NODES = {\n",
        "    \"StatementExpression\",\n",
        "    \"ReturnStatement\",\n",
        "    \"IfStatement\",\n",
        "    \"ForStatement\",\n",
        "    \"WhileStatement\",\n",
        "    \"DoStatement\",\n",
        "    \"SwitchStatement\",\n",
        "    \"TryStatement\",\n",
        "    \"ThrowStatement\",\n",
        "    \"BreakStatement\",\n",
        "    \"ContinueStatement\",\n",
        "    \"BlockStatement\",\n",
        "}\n",
        "\n",
        "WRAP_TEMPLATE = \"\"\"public class Dummy {{\n",
        "    {method_code}\n",
        "}}\"\"\"\n",
        "\n",
        "\n",
        "def wrap_method(method_code: str) -> str:\n",
        "    return WRAP_TEMPLATE.format(method_code=method_code)\n",
        "\n",
        "\n",
        "def iter_children(node):\n",
        "    for child in node.children:\n",
        "        if child is None:\n",
        "            continue\n",
        "        if isinstance(child, list):\n",
        "            for item in child:\n",
        "                if item is not None:\n",
        "                    yield item\n",
        "        else:\n",
        "            yield child\n",
        "\n",
        "\n",
        "def get_node_label(node) -> str | None:\n",
        "    if hasattr(node, \"name\") and node.name:\n",
        "        return str(node.name)\n",
        "    if hasattr(node, \"member\") and node.member:\n",
        "        return str(node.member)\n",
        "    if hasattr(node, \"value\") and node.value is not None:\n",
        "        return str(node.value)\n",
        "    if hasattr(node, \"operator\") and node.operator:\n",
        "        return str(node.operator)\n",
        "    if hasattr(node, \"type\") and isinstance(node.type, str):\n",
        "        return str(node.type)\n",
        "    return None\n",
        "\n",
        "\n",
        "def compute_line_offsets(code: str) -> list[int]:\n",
        "    offsets = [0]\n",
        "    for idx, ch in enumerate(code):\n",
        "        if ch == \"\\n\":\n",
        "            offsets.append(idx + 1)\n",
        "    return offsets\n",
        "\n",
        "\n",
        "def line_col_to_offset(code: str, line: int, col: int) -> int | None:\n",
        "    if line <= 0 or col <= 0:\n",
        "        return None\n",
        "    line_offsets = compute_line_offsets(code)\n",
        "    if line > len(line_offsets):\n",
        "        return None\n",
        "    return line_offsets[line - 1] + (col - 1)\n",
        "\n",
        "\n",
        "def offset_to_line_col(code: str, offset: int) -> tuple[int, int]:\n",
        "    if offset < 0:\n",
        "        return (1, 1)\n",
        "    line_offsets = compute_line_offsets(code)\n",
        "    line = 1\n",
        "    for i, start in enumerate(line_offsets, 1):\n",
        "        if start <= offset:\n",
        "            line = i\n",
        "        else:\n",
        "            break\n",
        "    col = offset - line_offsets[line - 1] + 1\n",
        "    return (line, col)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4469b793",
      "metadata": {},
      "outputs": [],
      "source": [
        "def build_ast_graph(code: str):\n",
        "    tree = javalang.parse.parse(wrap_method(code))\n",
        "\n",
        "    nodes = []\n",
        "    parents = []\n",
        "    children = []\n",
        "    id_to_index = {}\n",
        "\n",
        "    def is_wrapper(node) -> bool:\n",
        "        if isinstance(node, javalang.tree.CompilationUnit):\n",
        "            return True\n",
        "        if isinstance(node, javalang.tree.ClassDeclaration) and getattr(node, \"name\", None) == \"Dummy\":\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "    def visit(node, parent_idx: int | None):\n",
        "        if not isinstance(node, javalang.tree.Node):\n",
        "            return\n",
        "        if is_wrapper(node):\n",
        "            for child in iter_children(node):\n",
        "                visit(child, parent_idx)\n",
        "            return\n",
        "\n",
        "        idx = len(nodes)\n",
        "        id_to_index[id(node)] = idx\n",
        "\n",
        "        label = get_node_label(node)\n",
        "        line = None\n",
        "        col = None\n",
        "        if getattr(node, \"position\", None):\n",
        "            line = node.position.line\n",
        "            col = node.position.column\n",
        "        start_pos = line_col_to_offset(code, line, col) if line and col else None\n",
        "        end_pos = start_pos + len(label) if (start_pos is not None and label) else start_pos\n",
        "\n",
        "        nodes.append(\n",
        "            {\n",
        "                \"raw\": node,\n",
        "                \"node_type\": node.__class__.__name__,\n",
        "                \"label\": label,\n",
        "                \"line\": line,\n",
        "                \"col\": col,\n",
        "                \"start_pos\": start_pos,\n",
        "                \"end_pos\": end_pos,\n",
        "            }\n",
        "        )\n",
        "        parents.append(parent_idx)\n",
        "        children.append([])\n",
        "        if parent_idx is not None:\n",
        "            children[parent_idx].append(idx)\n",
        "\n",
        "        for child in iter_children(node):\n",
        "            visit(child, idx)\n",
        "\n",
        "    visit(tree, None)\n",
        "\n",
        "    edges = []\n",
        "    edge_types = []\n",
        "\n",
        "    def add_edge(src: int, dst: int, rel: str):\n",
        "        edges.append((src, dst))\n",
        "        edge_types.append(RELATION_TO_ID[rel])\n",
        "\n",
        "    # AST edges\n",
        "    for parent_idx, child_list in enumerate(children):\n",
        "        for child_idx in child_list:\n",
        "            add_edge(parent_idx, child_idx, \"AST_CHILD\")\n",
        "            add_edge(child_idx, parent_idx, \"AST_PARENT\")\n",
        "\n",
        "    # CFG edges (heuristic)\n",
        "    for parent_idx, child_list in enumerate(children):\n",
        "        stmt_children = [c for c in child_list if nodes[c][\"node_type\"] in STATEMENT_NODES]\n",
        "        for a, b in zip(stmt_children, stmt_children[1:]):\n",
        "            add_edge(a, b, \"CFG_NEXT\")\n",
        "\n",
        "    for idx, node in enumerate(nodes):\n",
        "        node_type = node[\"node_type\"]\n",
        "        raw = node[\"raw\"]\n",
        "\n",
        "        if node_type == \"IfStatement\":\n",
        "            then_node = getattr(raw, \"then_statement\", None)\n",
        "            else_node = getattr(raw, \"else_statement\", None)\n",
        "            then_idx = id_to_index.get(id(then_node))\n",
        "            else_idx = id_to_index.get(id(else_node))\n",
        "            if then_idx is not None:\n",
        "                add_edge(idx, then_idx, \"CFG_TRUE\")\n",
        "            if else_idx is not None:\n",
        "                add_edge(idx, else_idx, \"CFG_FALSE\")\n",
        "\n",
        "        if node_type in {\"ForStatement\", \"WhileStatement\", \"DoStatement\"}:\n",
        "            body = getattr(raw, \"body\", None)\n",
        "            body_idx = id_to_index.get(id(body))\n",
        "            if body_idx is not None:\n",
        "                add_edge(idx, body_idx, \"CFG_LOOP\")\n",
        "\n",
        "    # DFG edges (simple def-use)\n",
        "    last_def = {}\n",
        "\n",
        "    def extract_assigned_name(raw_node) -> str | None:\n",
        "        target = getattr(raw_node, \"expressionl\", None) or getattr(raw_node, \"left\", None)\n",
        "        if target is None:\n",
        "            return None\n",
        "        if hasattr(target, \"member\") and target.member:\n",
        "            return str(target.member)\n",
        "        if hasattr(target, \"name\") and target.name:\n",
        "            return str(target.name)\n",
        "        return None\n",
        "\n",
        "    for idx, node in enumerate(nodes):\n",
        "        node_type = node[\"node_type\"]\n",
        "        label = node[\"label\"]\n",
        "        raw = node[\"raw\"]\n",
        "\n",
        "        if node_type in {\"VariableDeclarator\", \"FormalParameter\"} and label:\n",
        "            last_def[label] = idx\n",
        "\n",
        "        if node_type == \"Assignment\":\n",
        "            assigned = extract_assigned_name(raw)\n",
        "            if assigned:\n",
        "                last_def[assigned] = idx\n",
        "\n",
        "        if node_type == \"MemberReference\" and label:\n",
        "            if label in last_def:\n",
        "                def_idx = last_def[label]\n",
        "                add_edge(def_idx, idx, \"DEF_USE\")\n",
        "                add_edge(idx, def_idx, \"USE_DEF\")\n",
        "\n",
        "    return nodes, parents, children, edges, edge_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "980bc46c",
      "metadata": {},
      "outputs": [],
      "source": [
        "def match_actions_to_nodes(code: str, nodes: list[dict], parents: list[int | None], actions):\n",
        "    action_map: dict[int, EditType] = {}\n",
        "\n",
        "    for action in actions:\n",
        "        node_type = action.node.node_type\n",
        "        label = action.node.label\n",
        "        pos = action.node.position\n",
        "        line = None\n",
        "        col = None\n",
        "        if pos is not None:\n",
        "            line, col = offset_to_line_col(code, pos[0])\n",
        "\n",
        "        candidates = [i for i, n in enumerate(nodes) if n[\"node_type\"] == node_type]\n",
        "        if label:\n",
        "            label_candidates = [i for i in candidates if nodes[i][\"label\"] == label]\n",
        "            if label_candidates:\n",
        "                candidates = label_candidates\n",
        "        if line:\n",
        "            line_candidates = [i for i in candidates if nodes[i][\"line\"] == line]\n",
        "            if line_candidates:\n",
        "                candidates = line_candidates\n",
        "\n",
        "        if not candidates:\n",
        "            continue\n",
        "\n",
        "        if col is not None:\n",
        "            candidates.sort(key=lambda i: abs((nodes[i][\"col\"] or col) - col))\n",
        "\n",
        "        matched_idx = candidates[0]\n",
        "        action_map[matched_idx] = action.action_type\n",
        "\n",
        "    # subtree changed\n",
        "    subtree_changed = [0] * len(nodes)\n",
        "    for idx in action_map.keys():\n",
        "        cur = parents[idx]\n",
        "        while cur is not None:\n",
        "            subtree_changed[cur] = 1\n",
        "            cur = parents[cur]\n",
        "\n",
        "    return action_map, subtree_changed\n",
        "\n",
        "\n",
        "def build_diff_features(action_map: dict[int, EditType], subtree_changed: list[int], num_nodes: int):\n",
        "    diff_feats = []\n",
        "    labels = []\n",
        "    for idx in range(num_nodes):\n",
        "        action = action_map.get(idx)\n",
        "        is_diff = 1 if action is not None else 0\n",
        "        action_none = 1 if action is None else 0\n",
        "        action_update = 1 if action == EditType.UPDATE else 0\n",
        "        action_delete = 1 if action == EditType.DELETE else 0\n",
        "        action_move = 1 if action == EditType.MOVE else 0\n",
        "        diff_feats.append([\n",
        "            is_diff,\n",
        "            action_none,\n",
        "            action_update,\n",
        "            action_delete,\n",
        "            action_move,\n",
        "            subtree_changed[idx],\n",
        "        ])\n",
        "        labels.append(1 if action in {EditType.UPDATE, EditType.DELETE} else 0)\n",
        "    return torch.tensor(diff_feats, dtype=torch.float), torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "\n",
        "def add_diff_edges(children, action_map, edges, edge_types):\n",
        "    changed_nodes = set(action_map.keys())\n",
        "    for idx in changed_nodes:\n",
        "        parent = None\n",
        "        for p, child_list in enumerate(children):\n",
        "            if idx in child_list:\n",
        "                parent = p\n",
        "                break\n",
        "        if parent is not None:\n",
        "            edges.append((idx, parent))\n",
        "            edge_types.append(RELATION_TO_ID[\"DIFF_PARENT\"])\n",
        "            for sibling in children[parent]:\n",
        "                if sibling == idx:\n",
        "                    continue\n",
        "                edges.append((idx, sibling))\n",
        "                edge_types.append(RELATION_TO_ID[\"DIFF_SIBLING\"])\n",
        "                edges.append((sibling, idx))\n",
        "                edge_types.append(RELATION_TO_ID[\"DIFF_SIBLING\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4b4bb777",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cpu\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at microsoft/graphcodebert-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if USE_CODE_EMBEDDINGS:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    encoder = AutoModel.from_pretrained(MODEL_NAME).to(device)\n",
        "    encoder.eval()\n",
        "else:\n",
        "    tokenizer = None\n",
        "    encoder = None\n",
        "\n",
        "\n",
        "def compute_code_embeddings(code: str, nodes: list[dict], children: list[list[int]]):\n",
        "    num_nodes = len(nodes)\n",
        "    if not USE_CODE_EMBEDDINGS:\n",
        "        return torch.zeros((num_nodes, 768), dtype=torch.float)\n",
        "\n",
        "    enc = tokenizer(\n",
        "        code,\n",
        "        return_tensors=\"pt\",\n",
        "        return_offsets_mapping=True,\n",
        "        truncation=True,\n",
        "        max_length=512,\n",
        "    )\n",
        "    offsets = enc.pop(\"offset_mapping\")[0].tolist()\n",
        "    enc = {k: v.to(device) for k, v in enc.items()}\n",
        "\n",
        "    with torch.inference_mode():\n",
        "        outputs = encoder(**enc)\n",
        "    token_embs = outputs.last_hidden_state[0].cpu()\n",
        "\n",
        "    node_embs = torch.zeros((num_nodes, token_embs.shape[-1]), dtype=torch.float)\n",
        "\n",
        "    for idx, node in enumerate(nodes):\n",
        "        start = node[\"start_pos\"]\n",
        "        end = node[\"end_pos\"]\n",
        "        if start is None or end is None or start == end:\n",
        "            continue\n",
        "        token_idxs = [\n",
        "            t for t, (s, e) in enumerate(offsets)\n",
        "            if not (s == 0 and e == 0) and s < end and e > start\n",
        "        ]\n",
        "        if token_idxs:\n",
        "            node_embs[idx] = token_embs[token_idxs].mean(dim=0)\n",
        "\n",
        "    # Aggregate from children for non-leaf nodes\n",
        "    for idx in reversed(range(num_nodes)):\n",
        "        if torch.all(node_embs[idx] == 0) and children[idx]:\n",
        "            child_embs = [node_embs[c] for c in children[idx] if torch.any(node_embs[c] != 0)]\n",
        "            if child_embs:\n",
        "                node_embs[idx] = torch.stack(child_embs).mean(dim=0)\n",
        "\n",
        "    return node_embs\n",
        "\n",
        "\n",
        "def compute_code_embeddings_batch(\n",
        "    codes: list[str],\n",
        "    nodes_list: list[list[dict]],\n",
        "    children_list: list[list[list[int]]],\n",
        "    batch_size: int = 8,\n",
        "):\n",
        "    if not USE_CODE_EMBEDDINGS:\n",
        "        return [torch.zeros((len(nodes), 768), dtype=torch.float) for nodes in nodes_list]\n",
        "\n",
        "    all_embs = []\n",
        "    for start in range(0, len(codes), batch_size):\n",
        "        batch_codes = codes[start : start + batch_size]\n",
        "        batch_nodes = nodes_list[start : start + batch_size]\n",
        "        batch_children = children_list[start : start + batch_size]\n",
        "\n",
        "        enc = tokenizer(\n",
        "            batch_codes,\n",
        "            return_tensors=\"pt\",\n",
        "            return_offsets_mapping=True,\n",
        "            truncation=True,\n",
        "            max_length=512,\n",
        "            padding=True,\n",
        "        )\n",
        "        offsets_batch = enc.pop(\"offset_mapping\").tolist()\n",
        "        enc = {k: v.to(device) for k, v in enc.items()}\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            outputs = encoder(**enc)\n",
        "        token_embs = outputs.last_hidden_state.cpu()\n",
        "\n",
        "        for i, nodes in enumerate(batch_nodes):\n",
        "            offsets = offsets_batch[i]\n",
        "            token_embs_i = token_embs[i]\n",
        "            num_nodes = len(nodes)\n",
        "\n",
        "            node_embs = torch.zeros((num_nodes, token_embs_i.shape[-1]), dtype=torch.float)\n",
        "\n",
        "            for idx, node in enumerate(nodes):\n",
        "                start_pos = node[\"start_pos\"]\n",
        "                end_pos = node[\"end_pos\"]\n",
        "                if start_pos is None or end_pos is None or start_pos == end_pos:\n",
        "                    continue\n",
        "                token_idxs = [\n",
        "                    t for t, (s, e) in enumerate(offsets)\n",
        "                    if not (s == 0 and e == 0) and s < end_pos and e > start_pos\n",
        "                ]\n",
        "                if token_idxs:\n",
        "                    node_embs[idx] = token_embs_i[token_idxs].mean(dim=0)\n",
        "\n",
        "            # Aggregate from children for non-leaf nodes\n",
        "            for idx in reversed(range(num_nodes)):\n",
        "                if torch.all(node_embs[idx] == 0) and batch_children[i][idx]:\n",
        "                    child_embs = [\n",
        "                        node_embs[c]\n",
        "                        for c in batch_children[i][idx]\n",
        "                        if torch.any(node_embs[c] != 0)\n",
        "                    ]\n",
        "                    if child_embs:\n",
        "                        node_embs[idx] = torch.stack(child_embs).mean(dim=0)\n",
        "\n",
        "            all_embs.append(node_embs)\n",
        "\n",
        "    return all_embs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "3d9819d2",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Node types: 59\n"
          ]
        }
      ],
      "source": [
        "def build_node_type_vocab(codes: list[str]):\n",
        "    node_types = set()\n",
        "    for code in tqdm(codes, desc=\"Collect node types\"):\n",
        "        try:\n",
        "            nodes, _, _, _, _ = build_ast_graph(code)\n",
        "            node_types.update(n[\"node_type\"] for n in nodes)\n",
        "        except Exception:\n",
        "            continue\n",
        "    return {t: i for i, t in enumerate(sorted(node_types))}\n",
        "\n",
        "\n",
        "# node_type_to_id = build_node_type_vocab(df[\"buggy_function\"].tolist())\n",
        "# if \"UNK\" not in node_type_to_id:\n",
        "#     node_type_to_id[\"UNK\"] = len(node_type_to_id)\n",
        "# print(f\"Node types: {len(node_type_to_id)}\")\n",
        "\n",
        "import joblib\n",
        "# joblib.dump(node_type_to_id, \"output/node_type_to_id.joblib\")\n",
        "node_type_to_id = joblib.load(\"output/node_type_to_id.joblib\")\n",
        "print(f\"Node types: {len(node_type_to_id)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "606a918e",
      "metadata": {},
      "outputs": [],
      "source": [
        "def add_diff_edges(children, parents, action_map, edges, edge_types):\n",
        "    changed_nodes = set(action_map.keys())\n",
        "    for idx in changed_nodes:\n",
        "        parent = parents[idx]\n",
        "        if parent is not None:\n",
        "            edges.append((idx, parent))\n",
        "            edge_types.append(RELATION_TO_ID[\"DIFF_PARENT\"])\n",
        "            for sibling in children[parent]:\n",
        "                if sibling == idx:\n",
        "                    continue\n",
        "                edges.append((idx, sibling))\n",
        "                edge_types.append(RELATION_TO_ID[\"DIFF_SIBLING\"])\n",
        "                edges.append((sibling, idx))\n",
        "                edge_types.append(RELATION_TO_ID[\"DIFF_SIBLING\"])\n",
        "\n",
        "\n",
        "def get_node_type_id(node_type: str) -> int:\n",
        "    return node_type_to_id.get(node_type, node_type_to_id[\"UNK\"])\n",
        "\n",
        "\n",
        "gumtree_diff = GumTreeDiff(gumtree_path=GUMTREE_PATH)\n",
        "\n",
        "\n",
        "def init_gumtree_worker(gumtree_path: str):\n",
        "    global gumtree_diff\n",
        "    gumtree_diff = GumTreeDiff(gumtree_path=gumtree_path)\n",
        "\n",
        "\n",
        "def build_graph_parts_worker(args):\n",
        "    buggy_code, fixed_code, method_id = args\n",
        "    try:\n",
        "        return build_graph_parts(buggy_code, fixed_code, method_id)\n",
        "    except Exception:\n",
        "        return None\n",
        "\n",
        "\n",
        "def build_graph_parts(buggy_code: str, fixed_code: str, method_id: str):\n",
        "    nodes, parents, children, edges, edge_types = build_ast_graph(buggy_code)\n",
        "\n",
        "    diff_result = gumtree_diff.diff(buggy_code, fixed_code)\n",
        "    action_map, subtree_changed = match_actions_to_nodes(buggy_code, nodes, parents, diff_result.actions)\n",
        "\n",
        "    diff_feats, labels = build_diff_features(action_map, subtree_changed, len(nodes))\n",
        "    add_diff_edges(children, parents, action_map, edges, edge_types)\n",
        "\n",
        "    if LABEL_PARENTS:\n",
        "        for idx, val in enumerate(labels.tolist()):\n",
        "            if val == 1 and parents[idx] is not None:\n",
        "                labels[parents[idx]] = 1\n",
        "\n",
        "    node_type_ids = torch.tensor([get_node_type_id(n[\"node_type\"]) for n in nodes], dtype=torch.long)\n",
        "\n",
        "    return {\n",
        "        \"buggy_code\": buggy_code,\n",
        "        \"nodes\": nodes,\n",
        "        \"parents\": parents,\n",
        "        \"children\": children,\n",
        "        \"edges\": edges,\n",
        "        \"edge_types\": edge_types,\n",
        "        \"diff_feats\": diff_feats,\n",
        "        \"labels\": labels,\n",
        "        \"node_type_ids\": node_type_ids,\n",
        "        \"method_id\": method_id,\n",
        "    }\n",
        "\n",
        "\n",
        "def build_graph_sample(\n",
        "    buggy_code: str,\n",
        "    fixed_code: str,\n",
        "    method_id: str,\n",
        "    code_embs: torch.Tensor | None = None,\n",
        "):\n",
        "    parts = build_graph_parts(buggy_code, fixed_code, method_id)\n",
        "\n",
        "    if code_embs is None:\n",
        "        code_embs = compute_code_embeddings(\n",
        "            parts[\"buggy_code\"], parts[\"nodes\"], parts[\"children\"]\n",
        "        )\n",
        "\n",
        "    x = torch.cat([code_embs, parts[\"diff_feats\"]], dim=1)\n",
        "\n",
        "    if parts[\"edges\"]:\n",
        "        edge_index = torch.tensor(parts[\"edges\"], dtype=torch.long).t().contiguous()\n",
        "        edge_type = torch.tensor(parts[\"edge_types\"], dtype=torch.long)\n",
        "    else:\n",
        "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "        edge_type = torch.empty((0,), dtype=torch.long)\n",
        "\n",
        "    data = Data(\n",
        "        x=x,\n",
        "        edge_index=edge_index,\n",
        "        edge_type=edge_type,\n",
        "        y=parts[\"labels\"],\n",
        "        node_type_ids=parts[\"node_type_ids\"],\n",
        "        method_id=parts[\"method_id\"],\n",
        "    )\n",
        "    return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "82721140",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data(x=[66, 774], edge_index=[2, 155], y=[66], edge_type=[155], node_type_ids=[66], method_id='0')\n",
            "x: torch.Size([66, 774])\n",
            "edge_index: torch.Size([2, 155])\n",
            "edge_type: torch.Size([155])\n",
            "y: torch.Size([66]), positives=1\n"
          ]
        }
      ],
      "source": [
        "sample = df.iloc[0]\n",
        "method_id = str(sample.get(\"method_id\", 0))\n",
        "\n",
        "example_graph = build_graph_sample(\n",
        "    sample[\"buggy_function\"],\n",
        "    sample[\"fixed_function\"],\n",
        "    method_id=method_id,\n",
        ")\n",
        "\n",
        "print(example_graph)\n",
        "print(f\"x: {example_graph.x.shape}\")\n",
        "print(f\"edge_index: {example_graph.edge_index.shape}\")\n",
        "print(f\"edge_type: {example_graph.edge_type.shape}\")\n",
        "print(f\"y: {example_graph.y.shape}, positives={int(example_graph.y.sum())}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "4ad333fe",
      "metadata": {},
      "outputs": [],
      "source": [
        "# data_list = []\n",
        "\n",
        "# subset = df.head(MAX_SAMPLES)\n",
        "# batch_parts = []\n",
        "# chunk_idx = 0\n",
        "# num_saved = 0\n",
        "# saved_files = []\n",
        "\n",
        "# for idx, row in enumerate(\n",
        "#     tqdm(subset.itertuples(index=False), total=len(subset), desc=\"Building graphs\")\n",
        "# ):\n",
        "#     try:\n",
        "#         method_id = str(getattr(row, \"method_id\", idx))\n",
        "#         parts = build_graph_parts(row.buggy_function, row.fixed_function, method_id)\n",
        "#         batch_parts.append(parts)\n",
        "\n",
        "#         if len(batch_parts) >= EMB_BATCH_SIZE:\n",
        "#             code_embs_list = compute_code_embeddings_batch(\n",
        "#                 [p[\"buggy_code\"] for p in batch_parts],\n",
        "#                 [p[\"nodes\"] for p in batch_parts],\n",
        "#                 [p[\"children\"] for p in batch_parts],\n",
        "#                 batch_size=len(batch_parts),\n",
        "#             )\n",
        "#             for parts, code_embs in zip(batch_parts, code_embs_list):\n",
        "#                 x = torch.cat([code_embs, parts[\"diff_feats\"]], dim=1)\n",
        "\n",
        "#                 if parts[\"edges\"]:\n",
        "#                     edge_index = torch.tensor(parts[\"edges\"], dtype=torch.long).t().contiguous()\n",
        "#                     edge_type = torch.tensor(parts[\"edge_types\"], dtype=torch.long)\n",
        "#                 else:\n",
        "#                     edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "#                     edge_type = torch.empty((0,), dtype=torch.long)\n",
        "\n",
        "#                 data_list.append(\n",
        "#                     Data(\n",
        "#                         x=x,\n",
        "#                         edge_index=edge_index,\n",
        "#                         edge_type=edge_type,\n",
        "#                         y=parts[\"labels\"],\n",
        "#                         node_type_ids=parts[\"node_type_ids\"],\n",
        "#                         method_id=parts[\"method_id\"],\n",
        "#                     )\n",
        "#                 )\n",
        "#             batch_parts = []\n",
        "\n",
        "#         if len(data_list) >= SAVE_CHUNK_SIZE:\n",
        "#             chunk_idx += 1\n",
        "#             output_path = os.path.join(OUTPUT_DIR, f\"rgcn_graphs_part{chunk_idx}.pt\")\n",
        "#             torch.save(data_list, output_path)\n",
        "#             saved_files.append(output_path)\n",
        "#             num_saved += len(data_list)\n",
        "#             data_list = []\n",
        "#     except Exception as exc:\n",
        "#         print(f\"Skip idx={idx}: {exc}\")\n",
        "#         continue\n",
        "\n",
        "# if batch_parts:\n",
        "#     code_embs_list = compute_code_embeddings_batch(\n",
        "#         [p[\"buggy_code\"] for p in batch_parts],\n",
        "#         [p[\"nodes\"] for p in batch_parts],\n",
        "#         [p[\"children\"] for p in batch_parts],\n",
        "#         batch_size=len(batch_parts),\n",
        "#     )\n",
        "#     for parts, code_embs in zip(batch_parts, code_embs_list):\n",
        "#         x = torch.cat([code_embs, parts[\"diff_feats\"]], dim=1)\n",
        "\n",
        "#         if parts[\"edges\"]:\n",
        "#             edge_index = torch.tensor(parts[\"edges\"], dtype=torch.long).t().contiguous()\n",
        "#             edge_type = torch.tensor(parts[\"edge_types\"], dtype=torch.long)\n",
        "#         else:\n",
        "#             edge_index = torch.empty((2, 0), dtype=torch.long)\n",
        "#             edge_type = torch.empty((0,), dtype=torch.long)\n",
        "\n",
        "#         data_list.append(\n",
        "#             Data(\n",
        "#                 x=x,\n",
        "#                 edge_index=edge_index,\n",
        "#                 edge_type=edge_type,\n",
        "#                 y=parts[\"labels\"],\n",
        "#                 node_type_ids=parts[\"node_type_ids\"],\n",
        "#                 method_id=parts[\"method_id\"],\n",
        "#             )\n",
        "#         )\n",
        "#     batch_parts = []\n",
        "\n",
        "# if data_list:\n",
        "#     chunk_idx += 1\n",
        "#     output_path = os.path.join(OUTPUT_DIR, f\"rgcn_graphs_part{chunk_idx}.pt\")\n",
        "#     torch.save(data_list, output_path)\n",
        "#     saved_files.append(output_path)\n",
        "#     num_saved += len(data_list)\n",
        "#     data_list = []\n",
        "\n",
        "# meta_path = os.path.join(OUTPUT_DIR, \"rgcn_graphs_meta.json\")\n",
        "# with open(meta_path, \"w\", encoding=\"utf-8\") as f:\n",
        "#     json.dump(\n",
        "#         {\n",
        "#             \"num_graphs\": num_saved,\n",
        "#             \"relations\": RELATIONS,\n",
        "#             \"relation_to_id\": RELATION_TO_ID,\n",
        "#             \"node_type_to_id\": node_type_to_id,\n",
        "#             \"node_type_emb_dim\": NODE_TYPE_EMB_DIM,\n",
        "#             \"diff_feature_dim\": DIFF_FEATURE_DIM,\n",
        "#             \"model_name\": MODEL_NAME,\n",
        "#             \"parts\": [os.path.basename(p) for p in saved_files],\n",
        "#             \"chunk_size\": SAVE_CHUNK_SIZE,\n",
        "#         },\n",
        "#         f,\n",
        "#         indent=2,\n",
        "#         ensure_ascii=True,\n",
        "#     )\n",
        "\n",
        "# print(f\"Saved {num_saved} graphs into {len(saved_files)} parts\")\n",
        "# print(f\"Saved metadata to {meta_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "199dfe71",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 20096 graphs from 2 files\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import random_split\n",
        "from torch_geometric.loader import DataLoader\n",
        "import glob\n",
        "\n",
        "candidates = sorted(glob.glob(os.path.join(OUTPUT_DIR, \"rgcn_graphs_part*.pt\")))\n",
        "if not candidates:\n",
        "    raise FileNotFoundError(\"No graph files found in output/rgcn_graphs\")\n",
        "\n",
        "data_list = []\n",
        "for path in candidates:\n",
        "    # Trust local files to load full objects (PyTorch 2.6 defaults to weights_only=True)\n",
        "    part = torch.load(path, weights_only=False)\n",
        "    data_list.extend(part)\n",
        "\n",
        "print(f\"Loaded {len(data_list)} graphs from {len(candidates)} files\")\n",
        "\n",
        "# Graph-level labels for bug detection\n",
        "for g in data_list:\n",
        "    g.graph_y = torch.tensor([1.0 if int(g.y.sum()) > 0 else 0.0], dtype=torch.float)\n",
        "\n",
        "# Train/val/test split\n",
        "num_total = len(data_list)\n",
        "train_size = int(0.8 * num_total)\n",
        "val_size = int(0.1 * num_total)\n",
        "test_size = num_total - train_size - val_size\n",
        "train_ds, val_ds, test_ds = random_split(\n",
        "    data_list,\n",
        "    [train_size, val_size, test_size],\n",
        "    generator=torch.Generator().manual_seed(42),\n",
        ")\n",
        "\n",
        "BATCH_SIZE = 8\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE)\n",
        "\n",
        "print(f\"Split: train={len(train_ds)}, val={len(val_ds)}, test={len(test_ds)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "b5583e07",
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.save(data_list, 'output/megadiff_graphs_list.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "75f8d5ce",
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch_geometric.data import InMemoryDataset\n",
        "\n",
        "# # data_list là list Data\n",
        "# print(type(data_list), len(data_list))\n",
        "\n",
        "# data, slices = InMemoryDataset.collate(data_list)\n",
        "# torch.save({\"data\": data, \"slices\": slices}, \"output/megadiff_graphs.pt\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6729788f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "20096 Data(x=[66, 774], edge_index=[2, 152], y=[66], edge_type=[152], node_type_ids=[66], method_id='0', graph_y=[1])\n"
          ]
        }
      ],
      "source": [
        "# load lại\n",
        "payload = torch.load(\"output/megadiff_graphs.pt\", weights_only=False)\n",
        "data, slices = payload[\"data\"], payload[\"slices\"]\n",
        "\n",
        "class MegadiffGraphDataset(InMemoryDataset):\n",
        "    def __init__(self, data, slices):\n",
        "        super().__init__(\".\")\n",
        "        self.data = data\n",
        "        self.slices = slices\n",
        "\n",
        "dataset = MegadiffGraphDataset(data, slices)\n",
        "print(len(dataset), dataset[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "da03e74b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall imbalance\n",
            "Node labels: pos=3170 neg=5168901 total=5172071 neg/pos=1630.57\n",
            "Graph labels: pos=2257 neg=17839 total=20096 neg/pos=7.90\n",
            "\n",
            "train imbalance\n",
            "  Node: pos=2567 neg=4126138 total=4128705 neg/pos=1607.38\n",
            "  Graph: pos=1838 neg=14238 total=16076 neg/pos=7.75\n",
            "\n",
            "val imbalance\n",
            "  Node: pos=313 neg=519548 total=519861 neg/pos=1659.90\n",
            "  Graph: pos=214 neg=1795 total=2009 neg/pos=8.39\n",
            "\n",
            "test imbalance\n",
            "  Node: pos=290 neg=523215 total=523505 neg/pos=1804.19\n",
            "  Graph: pos=205 neg=1806 total=2011 neg/pos=8.81\n"
          ]
        }
      ],
      "source": [
        "def count_labels(samples, label_attr: str):\n",
        "    pos = 0\n",
        "    total = 0\n",
        "    for g in samples:\n",
        "        labels = getattr(g, label_attr).view(-1)\n",
        "        pos += int(labels.sum().item())\n",
        "        total += int(labels.numel())\n",
        "    neg = total - pos\n",
        "    ratio = (neg / pos) if pos > 0 else float(\"inf\")\n",
        "    return pos, neg, total, ratio\n",
        "\n",
        "# Overall (node-level + graph-level)\n",
        "node_pos, node_neg, node_total, node_ratio = count_labels(data_list, \"y\")\n",
        "graph_pos, graph_neg, graph_total, graph_ratio = count_labels(data_list, \"graph_y\")\n",
        "\n",
        "print(\"Overall imbalance\")\n",
        "print(f\"Node labels: pos={node_pos} neg={node_neg} total={node_total} neg/pos={node_ratio:.2f}\")\n",
        "print(f\"Graph labels: pos={graph_pos} neg={graph_neg} total={graph_total} neg/pos={graph_ratio:.2f}\")\n",
        "\n",
        "# Per-split\n",
        "for name, ds in [(\"train\", train_ds), (\"val\", val_ds), (\"test\", test_ds)]:\n",
        "    npos, nneg, ntotal, nratio = count_labels(ds, \"y\")\n",
        "    gpos, gneg, gtotal, gratio = count_labels(ds, \"graph_y\")\n",
        "    print(f\"\\n{name} imbalance\")\n",
        "    print(f\"  Node: pos={npos} neg={nneg} total={ntotal} neg/pos={nratio:.2f}\")\n",
        "    print(f\"  Graph: pos={gpos} neg={gneg} total={gtotal} neg/pos={gratio:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "34ddb7bf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RGCNDetector(\n",
            "  (node_type_emb): Embedding(59, 64)\n",
            "  (convs): ModuleList(\n",
            "    (0): RGCNConv(838, 256, num_relations=10)\n",
            "    (1): RGCNConv(256, 256, num_relations=10)\n",
            "  )\n",
            "  (dropout): Dropout(p=0.2, inplace=False)\n",
            "  (node_head): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (graph_head): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from torch_geometric.nn.conv import RGCNConv\n",
        "\n",
        "class RGCNDetector(torch.nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        base_in_dim: int,\n",
        "        hidden_dim: int,\n",
        "        num_relations: int,\n",
        "        num_node_types: int,\n",
        "        node_type_emb_dim: int,\n",
        "        num_layers: int = 2,\n",
        "        dropout: float = 0.2,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.base_in_dim = base_in_dim\n",
        "        self.node_type_emb_dim = node_type_emb_dim\n",
        "        self.node_type_emb = torch.nn.Embedding(num_node_types, node_type_emb_dim)\n",
        "        conv_in_dim = base_in_dim + node_type_emb_dim\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        self.convs.append(RGCNConv(conv_in_dim, hidden_dim, num_relations=num_relations))\n",
        "        for _ in range(num_layers - 1):\n",
        "            self.convs.append(RGCNConv(hidden_dim, hidden_dim, num_relations=num_relations))\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.node_head = torch.nn.Linear(hidden_dim, 1)\n",
        "        self.graph_head = torch.nn.Linear(hidden_dim, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index, edge_type, batch = data.x, data.edge_index, data.edge_type, data.batch\n",
        "\n",
        "        if x.shape[1] == self.base_in_dim:\n",
        "            node_type_feats = self.node_type_emb(data.node_type_ids)\n",
        "            x = torch.cat([x, node_type_feats], dim=1)\n",
        "        elif x.shape[1] != self.base_in_dim + self.node_type_emb_dim:\n",
        "            raise ValueError(\n",
        "                f\"Unexpected x dim {x.shape[1]} (expected {self.base_in_dim} or {self.base_in_dim + self.node_type_emb_dim})\"\n",
        "            )\n",
        "\n",
        "        for conv in self.convs:\n",
        "            x = conv(x, edge_index, edge_type)\n",
        "            x = torch.relu(x)\n",
        "            x = self.dropout(x)\n",
        "        node_logits = self.node_head(x).squeeze(-1)\n",
        "        graph_emb = global_mean_pool(x, batch)\n",
        "        graph_logits = self.graph_head(graph_emb).squeeze(-1)\n",
        "        return node_logits, graph_logits\n",
        "\n",
        "\n",
        "expected_base_in_dim = 768 + DIFF_FEATURE_DIM\n",
        "raw_in_dim = data_list[0].x.shape[1]\n",
        "base_in_dim = (\n",
        "    expected_base_in_dim\n",
        "    if raw_in_dim in {expected_base_in_dim, expected_base_in_dim + NODE_TYPE_EMB_DIM}\n",
        "    else raw_in_dim\n",
        ")\n",
        "HIDDEN_DIM = 256\n",
        "model = RGCNDetector(\n",
        "    base_in_dim,\n",
        "    HIDDEN_DIM,\n",
        "    num_relations=len(RELATIONS),\n",
        "    num_node_types=len(node_type_to_id),\n",
        "    node_type_emb_dim=NODE_TYPE_EMB_DIM,\n",
        ").to(device)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "6fc615f7",
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 69\u001b[39m\n\u001b[32m     67\u001b[39m EPOCHS = \u001b[32m10\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, EPOCHS + \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     train_loss, train_node, train_graph = \u001b[43mrun_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     70\u001b[39m     val_loss, val_node, val_graph = run_epoch(val_loader, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m     71\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     72\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     73\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtrain_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m val_loss=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mnode_f1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_node[\u001b[32m2\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m node_acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_node[\u001b[32m3\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgraph_f1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_graph[\u001b[32m2\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m graph_acc=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_graph[\u001b[32m3\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36mrun_epoch\u001b[39m\u001b[34m(loader, is_train)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_train:\n\u001b[32m     54\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m     optimizer.step()\n\u001b[32m     58\u001b[39m total_loss += loss.item()\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\CodeBuggy\\.venv\\Lib\\site-packages\\torch\\_tensor.py:625\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    615\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    617\u001b[39m         Tensor.backward,\n\u001b[32m    618\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    623\u001b[39m         inputs=inputs,\n\u001b[32m    624\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\CodeBuggy\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:354\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    349\u001b[39m     retain_graph = create_graph\n\u001b[32m    351\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    352\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    353\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m354\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    356\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    357\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    359\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    360\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    361\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    362\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32me:\\CodeBuggy\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:841\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    839\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    840\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    842\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "def compute_pos_weight(samples, label_attr: str):\n",
        "    labels = []\n",
        "    for g in samples:\n",
        "        labels.append(getattr(g, label_attr).view(-1).float())\n",
        "    all_labels = torch.cat(labels, dim=0)\n",
        "    pos = all_labels.sum().item()\n",
        "    neg = all_labels.numel() - pos\n",
        "    if pos == 0:\n",
        "        return torch.tensor(1.0)\n",
        "    return torch.tensor(neg / pos)\n",
        "\n",
        "\n",
        "node_pos_weight = compute_pos_weight(train_ds, \"y\")\n",
        "graph_pos_weight = compute_pos_weight(train_ds, \"graph_y\")\n",
        "\n",
        "node_criterion = torch.nn.BCEWithLogitsLoss(pos_weight=node_pos_weight.to(device))\n",
        "graph_criterion = torch.nn.BCEWithLogitsLoss(pos_weight=graph_pos_weight.to(device))\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
        "\n",
        "\n",
        "def step_metrics(logits, labels):\n",
        "    probs = torch.sigmoid(logits)\n",
        "    preds = (probs > 0.5).long()\n",
        "    labels = labels.long()\n",
        "    tp = ((preds == 1) & (labels == 1)).sum().item()\n",
        "    fp = ((preds == 1) & (labels == 0)).sum().item()\n",
        "    fn = ((preds == 0) & (labels == 1)).sum().item()\n",
        "    tn = ((preds == 0) & (labels == 0)).sum().item()\n",
        "    precision = tp / (tp + fp + 1e-9)\n",
        "    recall = tp / (tp + fn + 1e-9)\n",
        "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
        "    acc = (tp + tn) / max(tp + tn + fp + fn, 1)\n",
        "    return precision, recall, f1, acc\n",
        "\n",
        "\n",
        "def run_epoch(loader, is_train: bool):\n",
        "    model.train() if is_train else model.eval()\n",
        "    total_loss = 0.0\n",
        "    node_stats = []\n",
        "    graph_stats = []\n",
        "    with torch.set_grad_enabled(is_train):\n",
        "        for batch in loader:\n",
        "            batch = batch.to(device)\n",
        "            node_logits, graph_logits = model(batch)\n",
        "            node_labels = batch.y.float()\n",
        "            graph_labels = batch.graph_y.view(-1).float()\n",
        "\n",
        "            node_loss = node_criterion(node_logits, node_labels)\n",
        "            graph_loss = graph_criterion(graph_logits, graph_labels)\n",
        "            loss = node_loss + graph_loss\n",
        "\n",
        "            if is_train:\n",
        "                optimizer.zero_grad()\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            node_stats.append(step_metrics(node_logits.detach().cpu(), node_labels.detach().cpu()))\n",
        "            graph_stats.append(step_metrics(graph_logits.detach().cpu(), graph_labels.detach().cpu()))\n",
        "\n",
        "    node_metrics = np.mean(node_stats, axis=0)\n",
        "    graph_metrics = np.mean(graph_stats, axis=0)\n",
        "    return total_loss / max(len(loader), 1), node_metrics, graph_metrics\n",
        "\n",
        "\n",
        "EPOCHS = 10\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_loss, train_node, train_graph = run_epoch(train_loader, True)\n",
        "    val_loss, val_node, val_graph = run_epoch(val_loader, False)\n",
        "    print(\n",
        "        f\"Epoch {epoch:02d} | \"\n",
        "        f\"train_loss={train_loss:.4f} val_loss={val_loss:.4f} | \"\n",
        "        f\"node_f1={val_node[2]:.4f} node_acc={val_node[3]:.4f} | \"\n",
        "        f\"graph_f1={val_graph[2]:.4f} graph_acc={val_graph[3]:.4f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc14ba47",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test | loss=4.0097 | node_precision=0.0278 node_recall=0.2500 node_f1=0.0500 node_acc=0.9912 | graph_precision=0.0000 graph_recall=0.0000 graph_f1=0.0000 graph_acc=0.8125\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_node, test_graph = run_epoch(test_loader, False)\n",
        "print(\n",
        "    f\"Test | loss={test_loss:.4f} | \"\n",
        "    f\"node_precision={test_node[0]:.4f} node_recall={test_node[1]:.4f} node_f1={test_node[2]:.4f} node_acc={test_node[3]:.4f} | \"\n",
        "    f\"graph_precision={test_graph[0]:.4f} graph_recall={test_graph[1]:.4f} graph_f1={test_graph[2]:.4f} graph_acc={test_graph[3]:.4f}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "acfc11a5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to output/rgcn_graphs\\rgcn_detector.pt\n"
          ]
        }
      ],
      "source": [
        "MODEL_OUT = os.path.join(OUTPUT_DIR, \"rgcn_detector.pt\")\n",
        "torch.save(\n",
        "    {\n",
        "        \"model_state\": model.state_dict(),\n",
        "        \"base_in_dim\": base_in_dim,\n",
        "        \"hidden_dim\": HIDDEN_DIM,\n",
        "        \"relations\": RELATIONS,\n",
        "        \"node_type_to_id\": node_type_to_id,\n",
        "    },\n",
        "    MODEL_OUT,\n",
        ")\n",
        "print(f\"Saved model to {MODEL_OUT}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
